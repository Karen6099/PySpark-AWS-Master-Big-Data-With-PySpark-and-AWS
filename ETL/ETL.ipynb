{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b5d555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|This is a Japanes...|\n",
      "|The team members ...|\n",
      "|As the years pass...|\n",
      "|If you don't like...|\n",
      "|He was disappoint...|\n",
      "|When he encounter...|\n",
      "|Situps are a terr...|\n",
      "|Toddlers feeding ...|\n",
      "|Edith could decid...|\n",
      "|Her daily goal wa...|\n",
      "|Tomorrow will bri...|\n",
      "|His son quipped t...|\n",
      "|He wondered why a...|\n",
      "|If my calculator ...|\n",
      "|The hummingbird's...|\n",
      "|He went on a whis...|\n",
      "|This is the last ...|\n",
      "|I come from a tri...|\n",
      "|The delicious aro...|\n",
      "|Weather is not tr...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, explode, lit\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ETL\").getOrCreate()\n",
    "\n",
    "df = spark.read.text(\"WordData.txt\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dadd20ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|   to|   88|\n",
      "|  the|   76|\n",
      "|    a|   76|\n",
      "|  was|   44|\n",
      "|   is|   40|\n",
      "|   he|   40|\n",
      "|   it|   36|\n",
      "|  The|   32|\n",
      "|   He|   28|\n",
      "|  and|   28|\n",
      "| that|   28|\n",
      "|  you|   24|\n",
      "|   in|   24|\n",
      "|   be|   24|\n",
      "|   of|   24|\n",
      "|    I|   24|\n",
      "|   so|   24|\n",
      "|  her|   24|\n",
      "|   if|   20|\n",
      "| from|   16|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# transformations\n",
    "df2 = df.withColumn(\"splitedData\", F.split(F.col(\"value\"), \" \"))\n",
    "df3 = df2.withColumn(\"words\", F.explode(F.col(\"splitedData\")))\n",
    "wordsDF = df3.select(\"words\")\n",
    "wordCount = wordsDF.groupBy(\"words\").count().orderBy(col(\"count\").desc())\n",
    "wordCount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c7c469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count data saved to wordcount_output_20251028_170032.csv\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "# NOTE: To write to PostgreSQL, you need the PostgreSQL JDBC driver JAR file\n",
    "# Download postgresql-42.7.3.jar from https://jdbc.postgresql.org/download/\n",
    "# and place it in your Spark jars directory or use --jars when submitting\n",
    "\n",
    "# For now, save to CSV instead (using pandas to avoid Windows Hadoop issues)\n",
    "try:\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    # Create unique filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = f\"wordcount_output_{timestamp}.csv\"\n",
    "    wordCount.toPandas().to_csv(output_file, index=False)\n",
    "    print(f\"Word count data saved to {output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {e}\")\n",
    "    print(\"Please close any open CSV files and try again.\")\n",
    "\n",
    "# Uncomment the JDBC code below once you have the PostgreSQL driver:\n",
    "# driver = \"org.postgresql.Driver\"\n",
    "# url = \"jdbc:postgresql://database-1.c0sanhw4ymut.us-west-2.rds.amazonaws.com/\"\n",
    "# table = \"ahmad_schema_pyspark.WordCount\"\n",
    "# user = \"postgres\"\n",
    "# password = \"\"\n",
    "# wordCount.write.format(\"jdbc\").option(\"driver\", driver).option(\"url\",url).option(\"dbtable\", table).option(\"mode\", \"append\").option(\"user\",user).option(\"password\", password).save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
