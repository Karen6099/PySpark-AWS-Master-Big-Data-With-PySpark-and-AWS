# PySpark Big Data Learning Repository

A comprehensive collection of PySpark examples and notebooks covering RDD operations, DataFrame manipulations, ETL processes, collaborative filtering, and streaming.

## ğŸ“ Project Structure

```
â”œâ”€â”€ DF/                          # DataFrame Operations
â”‚   â”œâ”€â”€ ComprehensiveDataFrameGuide.ipynb
â”‚   â”œâ”€â”€ Project.ipynb
â”‚   â”œâ”€â”€ Quiz1-4.ipynb
â”‚   â””â”€â”€ data files (StudentData.csv, OfficeData.csv, etc.)
â”œâ”€â”€ RDD/                         # Resilient Distributed Datasets
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ Count.ipynb
â”‚   â”‚   â”œâ”€â”€ Map.ipynb
â”‚   â”‚   â”œâ”€â”€ Filter.ipynb
â”‚   â”‚   â”œâ”€â”€ WordCount.ipynb
â”‚   â”‚   â””â”€â”€ 10+ more notebooks
â”‚   â””â”€â”€ data/
â”œâ”€â”€ ETL/                         # Extract, Transform, Load
â”‚   â”œâ”€â”€ ETL.ipynb
â”‚   â””â”€â”€ data files
â”œâ”€â”€ Collaborative Filtering/     # Recommendation Systems
â”‚   â”œâ”€â”€ collaborativeFiltering.ipynb
â”‚   â””â”€â”€ movie data (movies.csv, ratings.csv)
â””â”€â”€ Spark Streaming/             # Real-time Processing
    â”œâ”€â”€ Streaming_RDD.ipynb
    â”œâ”€â”€ Streaming_DF.ipynb
    â””â”€â”€ data/
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Java 17+ (for PySpark)
- PySpark installed

### Installation
```bash
pip install pyspark jupyterlab
```

### Run Examples
```bash
jupyter lab
```
Open any `.ipynb` file and run the cells sequentially.

## ğŸ“š Learning Modules

### 1. RDD Operations
- Basic transformations: `map`, `filter`, `flatMap`
- Aggregations: `reduceByKey`, `groupByKey`
- Actions: `count`, `collect`, `saveAsTextFile`
- Word count examples and quizzes

### 2. DataFrame Operations
- Creating DataFrames from CSV/RDD
- Schema management and data types
- Column operations: `select`, `withColumn`, `withColumnRenamed`
- Filtering and aggregations
- Comprehensive guide with examples

### 3. ETL Pipeline
- Extract: Reading text files
- Transform: Splitting, exploding, counting words
- Load: Saving to CSV (with PostgreSQL JDBC option)

### 4. Collaborative Filtering
- Movie recommendation system
- User-item rating analysis
- Matrix factorization concepts

### 5. Spark Streaming
- Real-time data processing
- DStream operations
- Structured Streaming with DataFrames

## ğŸ¯ Key Features

- âœ… **Hands-on Examples**: Each concept demonstrated with working code
- âœ… **Progressive Learning**: From basic RDDs to advanced streaming
- âœ… **Real Datasets**: Movie ratings, student data, office data
- âœ… **Quizzes & Exercises**: Test your understanding
- âœ… **Production Ready**: Includes error handling and best practices

## ğŸ“– Usage Tips

- Start with `RDD/notebooks/My First Notebook.ipynb` for basics
- Use `DF/ComprehensiveDataFrameGuide.ipynb` as DataFrame reference
- Run ETL pipeline in `ETL/ETL.ipynb` for complete workflow
- Check output files in respective directories after running notebooks

## ğŸ”§ Troubleshooting

- **Java Errors**: Ensure Java 17+ is installed and `JAVA_HOME` is set
- **File Permission Issues**: Close CSV files before running notebooks
- **Memory Issues**: Reduce data size or increase Spark memory settings
- **PostgreSQL JDBC**: Download driver JAR for database connectivity

---

*Based on Udemy course: [PySpark & AWS: Master Big Data with PySpark and AWS](https://www.udemy.com/course/pyspark-aws-master-big-data-with-pyspark-and-aws/)*